{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### PRE-RELEASE REVIEW: O'Reilly Intermediate Python Video Series\n",
      "#### Topic: What is Unicode? \n",
      "Source located in `nbsource/what-is-unicode.ipynb`. Automatically rendered from `UNKNOWN` on 2014-03-21 at 10:21:36.565850.\n",
      "#### AUTOMATICALLY GENERATED TEST NOTEBOOK - CHANGES WILL BE LOST\n",
      "#### To TEST this Notebook<br />1. select Cell | Run All, or step through with Shift/Enter<br />2. Notebook turns pink when testing starts<br />3. It turns white when the it runs to completion.<br />4. Please check the executed notebook for clarity and correctness.<br />Please [raise an issue](https://github.com/holdenweb/intermediate-python/issues) about anything you don't understand - by all means attach a saved copy of the notebook to add explanations or questions. Also please let us know about stuff you want to see covered under any heading in the outline.\n",
      "#### Your comments on the content are also welcome, particularly when [reported as issues](https://github.com/holdenweb/intermediate-python/issues)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "<img src=\"https://dl.dropboxusercontent.com/u/6117375/intermediate-notebooks/title_graphic.png\" />\n",
      "||| WORKING COPY ||| What is Unicode?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In Python 3 a lot of effort has gone into making the language useful to as wide a cross-section of the world's population as possible. Since not everyone uses the same alphabet, this means coping with a large variety of different characters\u2014\u2014many more than can be encoded in a single byte, which can store only 256 different values. \n",
      "\n",
      "The solution to these problems is called [_Unicode_[(https://en.wikipedia.org/wiki/Unicode), a system that allows programs to work with a very large character set indeed. Unicode should be used to represent any textual material your programs work with. Different communities habitually work with different subsets of the available characters, but theoretically at least it allows (for example) Japanese programmers to work on Hebrew text. Python's base string type, `str`, handles Unicode.\n",
      "\n",
      "While it's all very well to be able to represent such a wide range of characters, for them to be useful you have to be able to show them to the user as well! The mapping from Unicode characters to the _glyphs_ that are printed on the page or displayed on the screen is done by fonts. No single fontis capable of rendering all code point, but if you adopt appropriate fonts for your [_locale_](https://en.wikipedia.org/wiki/Locale) at least the most common characters will be properly represented. While you will still find that not all fonts are suited to your purposes things have been getting much better over the last ten years.\n",
      "\n",
      "Technically we should more accurately talk about _code points_ than characters, but informally both terms are used with the same meaning. Unicode code points are numbers from `0` through `0x10FFFF` (1,114,111 decimal)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(\"There are many characters in the Unicode set\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\u01ac\u0452\u0aef\u0ae8\u0aef \u03b1\u0ae8\u0aef \u028d\u03b1\u0e17y \u0aee\u0452\u03b1\u0ae8\u03b1\u0aee\u01ac\u0aef\u0ae8\u0abd \u00a1\u0e17 \u01ac\u0452\u0aef Unicode \u0abd\u0aef\u01ac\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\u3036\u24d7\u24d4\u24e1\u24d4 \u24d0\u24e1\u24d4 \u24dc\u24d0\u24dd\u24e8 \u24d2\u24d7\u24d0\u24e1\u24d0\u24d2\u3036\u24d4\u24e1\u24e2 \u24d8\u24dd \u3036\u24d7\u24d4 Unicode \u24e2\u24d4\u3036\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that you aren't just seiing different fonts rendering the same text here. You can get a numerical value for a single character with the built-in `ord()` function. As you see, the characters \"T\", \"\u01ac\" and \"\u3036\" are completely different code points."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ord(\"T\"), ord(\"\u01ac\"), ord(\"\u3036\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\u20ac\" # A one-character string"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Unicode EURO SYMBOL is represented in Unicode as code point number 8,364 decimal, 20ac hexadecimal. You can access the code point by passing a one-character Unicode string to the built-in `ord()` function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ord(\"\u20ac\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hex(ord(\"\u20ac\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Unicode escapes are just a way of representing Unicode characters without stepping outside the bounds of the ASCII character set. Follow the string `\"\\u\"` with the four-digit hexadecimal representation of the character's code point. It's really much easier to use Unicode source files, but if you find your production pipeline is constrained to ASCII at least you know you have a way of proceeding."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\\u20ac\" # The same string using a Unicode escape sequence"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Encodings"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Inside the Python interpreter, Unicode strings are kept in a regular format to make it easy to perform string  operations. The 32-bit representation is very simple, but as the attached diagram from the Python 3 documentation shows, such an encoding is somewhat wasteful.\n",
      "\n",
      "<img src=\"https://dl.dropboxusercontent.com/u/6117375/intermediate-notebooks/32-bit-unicode.png\" />\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When talking about interchange-standard representations, everyone has to conform to the same standards. Different computer architectures represent 32-bit numbers differently (in short, some put the MOST significant byte at the lowest address, some at the highest) so the two different types would, using their natural architectures, convert the same internal Unicode string to different byestreams. In a world where we must communicate with each other, such a situation cannot be tolerated.\n",
      "\n",
      "Further, this would represent a huge waste of bandwidth and storage space. In many texts most characters are in the 0-255 range. While computer memory has grown fast enough to make this an acceptable internal representation in memory, it would take four times as much network bandwidth and four times as much storage as an equivalent ASCII string. So compromises were sought, leading to a number of standardized _encodings_ of Unicode. These encodings are ways to represent Unicode (or a subset of it) for transmission and storage in a reasonably efficient manner.\n",
      "\n",
      "External media communicate in terms of bytes. Whenever you read a bytestream containing Unicode (usually using network or binary file operations) you should immediately ___decode___ it, converting the encoded byte stream into Unicode. Similarly, when writing a binary file or network stream the Unicode has to be ___encoded___ before it is stored or transmitted. One important feature of communicating Unicode is that both ends of a network connection must have some way to agree on the encoding to use. In the web's HTTP protocol, for example, the encoding in use can be specified in the headers.\n",
      "\n",
      "The [Python documentation on encodings](http://docs.python.org/3/howto/unicode.html#encodings) is a valuable source of further information. We do not claim do have done much more than scratch the surface here. In essence, and encoding for a particular application or region will try to make the most frequent characters those with the shortest encodings."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By default Python expects program source files to be encoded in UTF-8, a common Unicode encoding (you can indicate a different encoding within the file, but this is rarely necessary). This means if your editing system is Unicode-capable (as the IPython Notebook is, being web-based) you can write Unicode characters in your string literals. Indeed, recently Python started to allow alphabetic characters from other alphabets in identifiers. This allows programmers to use variable names that seem more natural to them, though of course the keywords remain stubbornly in English.\n",
      "\n",
      "Conveniently, ASCII is a proper subset of Unicode (_i.e._ each ASCII character is represented as a byte containing the same ASCII character code) so ASCII files are also acceptable. In ASCII, though, unlike in UTF-8, you have no way of inserting fancy characters (they can't be encoded in ASCII) and so you have to resort to _Unicode escape sequences_ for the less common characters."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We'll have more to say about encodings when we talk about communicating in Unicode with the outside world."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}